{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección De Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros para la carga y preprocesamiento de datos\n",
    "CLASS_FILTER_AMOUNT = 50           # Número de clases a clasificar\n",
    "IMAGE_SIZE = 224                   # Tamaño de la imagen de entrada (224x224)\n",
    "BATCH_SIZE = 64                    # Tamaño del batch para entrenamiento\n",
    "\n",
    "# Hiperparámetros de entrenamiento\n",
    "NON_DOWNSAMPLING_KERNEL_SIZE = 3   # Tamaño del kernel para convoluciones sin downsampling\n",
    "DOWNSAMPLING_KERNEL_SIZE = 1       # Tamaño del kernel para convoluciones con downsampling\n",
    "NON_DOWNSAMPLING_STRIDE = 1        # Stride para convoluciones sin downsampling\n",
    "DOWNSAMPLING_STRIDE = 2            # Stride para convoluciones con downsampling\n",
    "PADDING_SIZE = 1\n",
    "RESNET20_LAYERS = 3                # Padding para las convoluciones\n",
    "\n",
    "# Hiperparámetros de regularización y optimización\n",
    "EARLY_PATIENCE = 13                # Paciencia para early stopping\n",
    "DROPOUT_RATE_CONV = 0.25           # Tasa de dropout para capas convolucionales (si se utiliza)\n",
    "DROPOUT_RATE_FC1 = 0.4             # Tasa de dropout para la capa totalmente conectada (ajustada para evitar pérdida excesiva de información)\n",
    "LEARNING_RATE = 0.001              # Tasa de aprendizaje\n",
    "NORM_LAYER_INIT_WEIGHT = 1         # Valor de inicialización para pesos de BatchNorm\n",
    "NORM_LAYER_INIT_BIAS = 0           # Valor de inicialización para bias de BatchNorm\n",
    "MOMENTUM = 0.9                     # Momentum para el optimizador\n",
    "EPOCHS = 100                       # Número de épocas de entrenamiento\n",
    "SCHEDULER_PATIENCE = 6             # Paciencia para el scheduler de tasa de aprendizaje\n",
    "SCHEDULER_FACTOR = 0.2             # Factor de reducción para el scheduler\n",
    "WEIGHT_DECAY = 0.0001              # Peso de regularización L2\n",
    "\n",
    "# Hiperparámetros de seguridad\n",
    "CHECKPOINT_PATH = './saved_models/plantnet_300k_resnet34_checkpoint.pth' # Ruta para guardar el checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import and dataset download.\n",
    "\n",
    "In the next block, the import of the necessary libraries for the operation of the convolutional neural network takes place, together with secondary tools for auxiliary tasks such as graphing, etc. In addition, the set of images to be classified, belonging to a dataset hosted in the Kaggle platform, is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/Dev/Plant-Buddies/backend/model/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import torch\n",
    "import os\n",
    "from torch import tensor\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import ResNet34_Weights, resnet34\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# We begin by downloading the required dataset from the kaggle platform.\n",
    "# The selected dataset is PlantNet-300k by Noah Badoa. It contains approximately 300k images from several plant species.\n",
    "\n",
    "def download_dataset(dataset_name, version = None, path = None, force_download = False):\n",
    "    source = f\"{dataset_name}/versions/{version}\" if version else dataset_name\n",
    "    return kagglehub.dataset_download(\n",
    "        source,\n",
    "        path = path,\n",
    "        force_download = force_download\n",
    "    )\n",
    "\n",
    "dataset_path = download_dataset(dataset_name = \"noahbadoa/plantnet-300k-images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the set of classes with the highest number of images.\n",
    "\n",
    "Then, according to the number of images in the dataset for each of the classes, we will filter out those with the fifty largest numbers. We aim to facilitate and adapt the model to an adequate classification capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fifty most populated classes are:\n",
      "---------------------------------\n",
      "\n",
      "['1363227', '1392475', '1356022', '1364099', '1355937', '1359517', '1357330', '1358752', '1359620', '1363128', '1363991', '1355936', '1394460', '1363740', '1394994', '1364173', '1359616', '1364164', '1361824', '1361823', '1397364', '1358095', '1363130', '1389510', '1374048', '1367432', '1409238', '1397268', '1393614', '1356781', '1369887', '1393241', '1394420', '1398178', '1408774', '1435714', '1394591', '1385937', '1355932', '1358094', '1393425', '1393423', '1398592', '1408961', '1358133', '1358766', '1361656', '1384485', '1356257', '1358689']\n"
     ]
    }
   ],
   "source": [
    "# Specifying the paths to the training, evaluation and test directories.\n",
    "subpath = 'plantnet_300K'\n",
    "train_path = os.path.join(dataset_path, f\"{subpath}/images_train\")\n",
    "val_path = os.path.join(dataset_path, f\"{subpath}/images_val\")\n",
    "test_path = os.path.join(dataset_path, f\"{subpath}/images_test\")\n",
    "\n",
    "# We iterate trough the training directory to get the total number of images of each class\n",
    "class_count = []\n",
    "for class_id in os.listdir(train_path):\n",
    "    class_dir = os.path.join(train_path, class_id)\n",
    "    num_images = len(os.listdir(class_dir))\n",
    "    class_count.append((class_id, num_images))\n",
    "\n",
    "# Once we have the number of images of each class, we sort the array and filter the desired ones\n",
    "class_filter_amount = 50\n",
    "class_count.sort(key = lambda x: x[1], reverse = True)\n",
    "top_classes = [cls[0] for cls in class_count[:CLASS_FILTER_AMOUNT]]\n",
    "\n",
    "# Printing out the ids of the 50 most populated classes.\n",
    "print(f\"\\nFifty most populated classes are:\\n---------------------------------\\n\\n{top_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of datasets filtered by the obtained classes.\n",
    "\n",
    "From the test, training and validation directories, several datasets are created, filtering out those images not corresponding to the allowed classes. A python class is implemented by extending ‘ImageFolder’, manipulating its properties as appropriate to obtain the expected results. In addition, the labels associated with each image in a dataset are reassigned so that they belong to a range between zero and the total number of classes minus one. Finally, a primitive transformation is applied to each of the images in the data sets, manipulating the size and shape of the images (tensor transformation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetNet300K_Filtered_Dataset(datasets.ImageFolder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Data classes extending ‘ImageFolder’. Responsible for creating exclusionary datasets, reasigning labels and applying\n",
    "    unnormalized transformations.\n",
    "\n",
    "    Attributes\n",
    "    -----------------------------------\n",
    "    path (str): path to the folder where the set of images to be filtered is located.\n",
    "    allowed_classes (list): list with the set of class names to keep. \n",
    "    tranform (callable): primitive set of transformations to apply to each filtered image.\n",
    "    loader (callable): function in charge of loading the set of images from the specified path.\n",
    "    is_valid_file (callable): function that defines if a found file is valid or not at the time of loading.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, allowed_classes, transform=None, loader=datasets.folder.default_loader, is_valid_file=None):\n",
    "        # The ‘Image Folder’ object is initialized with the received attributes.\n",
    "        super().__init__(path, transform=transform, loader=loader, is_valid_file=is_valid_file)\n",
    "        \n",
    "        # The new mapping is created between the automatically originated tags for each image and the class number to which they belong.\n",
    "        self.allowed_classes = allowed_classes\n",
    "        self.new_class_to_idx = {class_name: idx for idx, class_name in enumerate(allowed_classes)}\n",
    "        \n",
    "        # The process of filtering and reassigning labels is performed.\n",
    "        filtered_samples = []\n",
    "        for path, orig_label in self.samples:\n",
    "            class_name = self.classes[orig_label]\n",
    "            if class_name in self.allowed_classes:\n",
    "                new_label = self.new_class_to_idx[class_name]\n",
    "                filtered_samples.append((path, new_label))\n",
    "\n",
    "        # Properties 'samples', 'classes' and 'class_to_idx' are updated.\n",
    "        self.samples = filtered_samples\n",
    "        self.classes = allowed_classes\n",
    "        self.class_to_idx = self.new_class_to_idx\n",
    "\n",
    "unnormalized_transformation = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Defining training, test and validation datasets\n",
    "train_dataset = PlanetNet300K_Filtered_Dataset(train_path, top_classes, unnormalized_transformation)\n",
    "val_dataset = PlanetNet300K_Filtered_Dataset(val_path, top_classes, unnormalized_transformation)\n",
    "test_dataset = PlanetNet300K_Filtered_Dataset(test_path, top_classes, unnormalized_transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the global mean and standart desviation for each dataset\n",
    "\n",
    "The global mean and standard deviation of each of the datasets is calculated, in order to perform a normalization of the pixel values of the images. For this purpose, we use a method that accumulates the sum and sum of squares of all pixels in the dataset.\n",
    "\n",
    "The overall mean of the data set is calculated according to the following formula:\n",
    "\n",
    "$mean = \\frac{total\\,sum\\,of\\,pixels}{total\\,number\\,of\\,pixels}$\n",
    "\n",
    "The standard deviation follows the following formula:\n",
    "\n",
    "$std = \\sqrt{\\frac{total\\,sum\\,of\\,squares}{total\\,number\\,of\\,pixels} - (mean)^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset statistics\n",
      "---------------------------------------------------------------------------\n",
      "Train dataset mean: tensor([0.4399, 0.4692, 0.3228], device='cuda:0')\n",
      "Train dataset std: tensor([0.2337, 0.2185, 0.2297], device='cuda:0')\n",
      "\n",
      "Val dataset statistics\n",
      "---------------------------------------------------------------------------\n",
      "Val dataset mean: tensor([0.4403, 0.4687, 0.3238], device='cuda:0')\n",
      "Val dataset std: tensor([0.2345, 0.2186, 0.2302], device='cuda:0')\n",
      "\n",
      "Test dataset statistics\n",
      "---------------------------------------------------------------------------\n",
      "Test dataset mean: tensor([0.4407, 0.4702, 0.3237], device='cuda:0')\n",
      "Test dataset std: tensor([0.2340, 0.2182, 0.2297], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_std(dataset, batch_size = BATCH_SIZE, num_workers = 0, identifier = None):\n",
    "    \"\"\"\n",
    "    Computes the maan and standard desviation of a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------------------------------------\n",
    "    dataset (ImageFolder): the dataset on which the operations are going to be based\n",
    "    batch_size (int): number of images from the dataset to be processed in parallel in a single segment.\n",
    "    num_workers (int): indicates the number of threads (parallel processes) that will be used to load the data.\n",
    "    \"\"\"\n",
    "\n",
    "    loader = DataLoader(dataset,batch_size = batch_size,num_workers = num_workers,pin_memory = True,shuffle = False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Defining variables to keep track of total sum of pixels, total sum of squares and total number of pixels\n",
    "    dataset_sum_of_pixels = torch.zeros(3, device = device)\n",
    "    dataset_sum_of_squares = torch.zeros(3, device = device)\n",
    "    dataset_number_of_pixels = 0\n",
    "\n",
    "    for batch, _ in loader:\n",
    "        \"\"\"\n",
    "        Each batch (set of images) is represented in the format [b, c, h, w] beign:\n",
    "        b: number of images\n",
    "        c: number of channels per image\n",
    "        h: height of each individual image\n",
    "        w: width of each individual image\n",
    "        \"\"\"\n",
    "        batch = batch.to(device)\n",
    "        samples = batch.size(0)\n",
    "        batch_number_of_pixels = samples * batch.size(2) * batch.size(3)\n",
    "        dataset_number_of_pixels += batch_number_of_pixels\n",
    "\n",
    "        # The dimensions of the images are flattened in the form {b, c, h * w}.\n",
    "        batch = batch.view(samples, batch.size(1), -1)\n",
    "\n",
    "        # Both sum and sum of squares of all images in the batch are obtained.\n",
    "        dataset_sum_of_pixels += batch.sum(dim = (0, 2))\n",
    "        dataset_sum_of_squares += (batch ** 2).sum(dim = (0, 2))\n",
    "\n",
    "    # Mean and standard deviation of the dataset are calculated and printed out.\n",
    "    mean = dataset_sum_of_pixels / dataset_number_of_pixels\n",
    "    std = torch.sqrt((dataset_sum_of_squares / dataset_number_of_pixels) - (mean ** 2))\n",
    "\n",
    "    print(f\"{identifier.capitalize()} dataset statistics\\n{'-' * 75}\")\n",
    "    print(f\"{identifier.capitalize()} dataset mean: {mean}\\n{identifier.capitalize()} dataset std: {std}\\n\")\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# Definition of mean and std variables for all testing, validation and training datasets\n",
    "train_mean, train_std = compute_mean_std(train_dataset, BATCH_SIZE, identifier = 'train')\n",
    "val_mean, val_std = compute_mean_std(val_dataset, BATCH_SIZE, identifier = 'val')\n",
    "test_mean, test_std = compute_mean_std(test_dataset, BATCH_SIZE, identifier = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of data loaders. Data Augmentation.\n",
    "\n",
    "In the next section, new transformations are defined allowing data augmentation techniques to be performed on the different sets of images. More specifically, on the training dataset, operations\n",
    "such as angular rotations, horizontal and vertical flips, modifications in contrast, brightness, saturation or other image parameters will be performed. The validation and testing datasets will\n",
    "be more lightly modified, as they will be used for tasks that do not require these techniques. The previously calculated mean and standard deviation values will be used to normalize the pixels of\n",
    "all images used in the model. After applying these transformations, data loaders are generated, whose main task is to programmatically introduce the images into the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining final transformation for train dataset.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), antialias = True),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation = 0.05, hue = 0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "# Defining final transformation for validation dataset.\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), antialias = True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(val_mean, val_std)\n",
    "])\n",
    "\n",
    "# Defining final tranformation for testing dataset.\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), antialias = True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(test_mean, test_std)\n",
    "])\n",
    "\n",
    "# Transformations are applied by generating new datasets that manifest these characteristics.\n",
    "train_dataset = PlanetNet300K_Filtered_Dataset(train_path, top_classes, train_transforms)\n",
    "test_dataset = PlanetNet300K_Filtered_Dataset(test_path, top_classes, test_transforms)\n",
    "val_dataset = PlanetNet300K_Filtered_Dataset(val_path, top_classes, val_transforms)\n",
    "\n",
    "# Defining data loaders for training, testing and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0, pin_memory = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0, pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "The early stopping mechanism for model training is established. This technique helps to avoid overfitting and save training time. To detect whether the model should be stopped, the loss produced in the\n",
    "validation stage is used, which if it does not decrease in a certain number of stages produces the stopping mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Early_Stopper:\n",
    "    \"\"\"\n",
    "    Class in charge of stopping the training process if the validation loss does not improve after a certain number of epochs.\n",
    "\n",
    "    Attributes\n",
    "    -----------------------------------\n",
    "    patience (int): number of epochs to wait before stopping the training process.\n",
    "    counter (int): number of epochs without improvement.\n",
    "    best_loss (float): best loss obtained during the training process.\n",
    "    stop (bool): flag that indicates if the training process should be stopped.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patience = EARLY_PATIENCE, callback = lambda **_: None):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.stop = False\n",
    "        self.callback = callback\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def counter(self):\n",
    "        return self._counter\n",
    "    \n",
    "    @counter.setter\n",
    "    def counter(self, value):\n",
    "        self._counter = value\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        \"\"\"\n",
    "        The method is called to update the counter and the best loss obtained during the training process.\n",
    "\n",
    "        Parameters\n",
    "        -----------------------------------\n",
    "        val_loss (float): loss obtained during the validation process.\n",
    "        \"\"\"\n",
    "        \n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.callback()\n",
    "                self.stop = True\n",
    "\n",
    "        return self.stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture. Layers and distribution.\n",
    "\n",
    "Convolutional network model characterized by having and using two types of structurally and functionally differentiated layers. First, we find the convolution layers, so called because of the\n",
    "mathematical operation they perform on the image pixels. They are mainly in charge of extracting the relevant features or patterns in the images in order to classify them later on. Secondly,\n",
    "we find the classification layers, whose function is to classify the features resulting from applying the different convolution layers. They are responsible for defining to which class each of\n",
    "the images that pass through the model belongs. Finally, a series of secondary but very important layers are used, including pooling layers, normalization layers and dropout layers, each with a\n",
    "role specified in the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a restnet34 model\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        ResNet34 model with a custom classifier. The model is pretrained with the ImageNet dataset.\n",
    "        First convolutional layer is described with 3 input channels, 64 output channels, kernel size of 3, stride of 1 and padding of 1.\n",
    "        First fully connected layer is described with ResNet34's number of features as input, 512 output features.\n",
    "        Second fully connected layer is described with 512 input features and number of classes as output features.\n",
    "        \"\"\"\n",
    "        self.resnet34 = resnet34(weights = ResNet34_Weights.IMAGENET1K_V1)\n",
    "        num_features = self.resnet34.fc.in_features\n",
    "        self.resnet34.conv1 = nn.Conv2d(3, 64, kernel_size = NON_DOWNSAMPLING_KERNEL_SIZE, stride = NON_DOWNSAMPLING_STRIDE, padding = PADDING_SIZE, bias = False)\n",
    "        self.resnet34.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_RATE_FC1),\n",
    "            nn.Linear(512, CLASS_FILTER_AMOUNT)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Section\n",
    "\n",
    "Function where the evaluation process of the parametric settings of the convolutional neural network will be carried out during the training procedure. The values collected in each evaluation process correspond to the comparison between the preditions and the real values, the reliability of the model and the accuracy of the predictions on failures and hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of the model on a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------------------------------------\n",
    "    model (nn.Module): model to be evaluated.\n",
    "    loader (DataLoader): data loader containing the dataset to be evaluated.\n",
    "    criterion (callable): loss function to be used.\n",
    "    device (torch.device): device on which the operations are going to be performed.\n",
    "    \"\"\" \n",
    "    \n",
    "    if not (device and criterion): raise Exception(\"Device and criterion must be specified on eval function.\")\n",
    "    \n",
    "    model.eval()\n",
    "    accurate_predictions = 0\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, target in loader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "            output = model(batch)\n",
    "            total_loss += criterion(output, target).item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            accurate_predictions += (predicted == target).sum().item()\n",
    "            total_samples += target.size(0)\n",
    "            predictions.extend(predicted.tolist())\n",
    "            targets.extend(target.tolist())\n",
    "\n",
    "    return predictions, targets, 100 * accurate_predictions / total_samples, total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load checkpoint functions.\n",
    "\n",
    "We define two functions, allowing us to store the weights and statistics provided by the neural network during the training process, so that, in case of an accident, we can restore the process from the last stored record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of chechpoint save function\n",
    "def save_checkpoint(model, scheduler, optimizer, epoch, tracking_lists, early_patience, path = CHECKPOINT_PATH):\n",
    "    \"\"\"\n",
    "    Saves the current state of the model, optimizer and scheduler to a file.\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------------------------------------\n",
    "    model (nn.Module): model to be saved.\n",
    "    scheduler (callable): scheduler to be saved.\n",
    "    optimizer (callable): optimizer to be saved.\n",
    "    epoch (int): current epoch.\n",
    "    tracking_lists (list): list of tracking values to be saved.\n",
    "    early_patience (int): current patience for early stopping.\n",
    "    path (str): path to the file where the model is going to be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'tracking': tracking_lists,\n",
    "        'early_patience': early_patience\n",
    "    }, path)\n",
    "\n",
    "# Definition of checkpoint load function\n",
    "def load_checkpoint(path):\n",
    "    \"\"\"\n",
    "    Loads the state of the model, optimizer and scheduler from a file.\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------------------------------------\n",
    "    path (str): path to the file where the model is going to be loaded.\n",
    "    \"\"\"\n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    return checkpoint\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Function that executes the training loop upon the neural network. The model is successively trained through a series of stages or epochs. In each of them, the parameters governing the performance of the network are reassigned according to the loss detected during the process. In addition, an evaluation of each of the iterative adjustments made to the parameters guiding the network is performed. Finally, data concerning the efficiency of the model after the training process are collected, including the hit and miss accuracies in each of the stages performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loaders, optimizer, criterion, scheduler, tracking_lists, callback, early_stopper, start_epoch, epochs = EPOCHS, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    \"\"\"\n",
    "    Trains the model on a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------------------------------------\n",
    "    model (nn.Module): model to be trained.\n",
    "    loaders (dict): dictionary containing the training and validation data loaders.\n",
    "    optimizer (callable): optimization algorithm to be used.\n",
    "    criterion (callable): loss function to be used.\n",
    "    epochs (int): number of epochs to train the model.\n",
    "    scheduler (callable): learning rate scheduler.\n",
    "    device (torch.device): device on which the operations are going to be performed.\n",
    "    early_stopper (callable): object in charge of stopping the training process if the validation loss does not improve.\n",
    "    callback (callable): function to be called during training loop to print statistics on display.\n",
    "    \"\"\"\n",
    "\n",
    "    if not (optimizer and criterion and early_stopper and scheduler and callback): raise Exception(\"Optimizer, criterion, early_stopper, scheduler and callback must be specified on train function.\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluating the model on the validation dataset before starting the training process\n",
    "    if start_epoch == 0:\n",
    "        val_predictions, val_targets, val_accuracy, val_loss = eval(model, loaders['val'], criterion, device)\n",
    "        callback(epoch = 0, val_accuracy = val_accuracy, val_loss = val_loss, train_accuracy = 0, train_loss = float('inf'))\n",
    "    \n",
    "    # Starting the training process\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        total_loss = 0\n",
    "        accurate_predictions = 0\n",
    "        total_samples = 0\n",
    "        model.train()\n",
    "\n",
    "        # Iterating through the training dataset\n",
    "        for i, (batch, target) in enumerate(loaders['train'], 1):\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            accurate_predictions += (predicted == target).sum().item()\n",
    "            total_samples += target.size(0)\n",
    "            if not i % 100:\n",
    "                print(f\"\\tEpoch {epoch + 1}, Batch {i}, Loss: {loss.item()}\")\n",
    "\n",
    "        # Evaluating the model for the current epoch \n",
    "        val_predictions, val_targets, val_accuracy, val_loss = eval(model, loaders['val'], criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Analyzing the performance of the model on the current epoch\n",
    "        train_accuracy = 100 * accurate_predictions / total_samples\n",
    "        train_loss = total_loss / len(loaders['train'])\n",
    "        tracking_lists['train_accuracies'].append(train_accuracy)\n",
    "        tracking_lists['train_losses'].append(train_loss)\n",
    "        tracking_lists['eval_accuracies'].append(val_accuracy)\n",
    "        tracking_lists['eval_losses'].append(val_loss)\n",
    "\n",
    "        # Printing out the statistics of the model on the current epoch\n",
    "        callback(epoch = epoch + 1, val_accuracy = val_accuracy, val_loss = val_loss, train_accuracy = train_accuracy, train_loss = train_loss)\n",
    "\n",
    "        # Saving the model periodically\n",
    "        if not (epoch + 1) % 5:\n",
    "            save_checkpoint(model, scheduler, optimizer, epoch + 1, tracking_lists, early_stopper.counter, CHECKPOINT_PATH)\n",
    "\n",
    "        # Checking if the training process should be stopped\n",
    "        if early_stopper(val_loss): break\n",
    "\n",
    "    return tracking_lists, val_predictions, val_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Configuration And Training Launch\n",
    "\n",
    "The final step is to configure the various parameters to be used during training, in the form of optimizations, selected loss function, scheduler, learning rate, etc. The callback functions that will be used to print the model analytics during learning are defined. The model is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/Dev/Plant-Buddies/backend/model/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     postrained_tracking_lists, val_predictions, val_targets \u001b[38;5;241m=\u001b[39m train(model, loaders, optimizer, criterion, scheduler, tracking_lists, callback, early_stopper, start_epoch, epochs \u001b[38;5;241m=\u001b[39m EPOCHS, device \u001b[38;5;241m=\u001b[39m device)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 75\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(start_epoch)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m postrained_tracking_lists, val_predictions, val_targets \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loaders, optimizer, criterion, scheduler, tracking_lists, callback, early_stopper, start_epoch, epochs, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 41\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m accurate_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m target)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def early_callback():\n",
    "    \"\"\"\n",
    "    Function in charge of printing out a message when the training process is stopped by the early stopper.\n",
    "    \"\"\"\n",
    "    print(\"\\nEarly stopping criterion met. Stopping training process.\\n\")\n",
    "\n",
    "def callback(epoch, val_accuracy, val_loss, train_accuracy, train_loss):\n",
    "    \"\"\"\n",
    "    Function in charge of printing out the statistics of the model on the current epoch.\n",
    "\n",
    "    Parameters\n",
    "    -------------------------------------------------------------\n",
    "    epoch (int): current epoch.\n",
    "    val_accuracy (float): accuracy of the model on the validation dataset.\n",
    "    val_loss (float): loss of the model on the validation dataset.\n",
    "    train_accuracy (float): accuracy of the model on the training dataset.\n",
    "    train_loss (float): loss of the model on the training dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Epoch: {epoch}, Train Accuracy: {train_accuracy:.2f}%, Train Loss: {train_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "def execute():\n",
    "    \"\"\"\n",
    "    Function in charge of executing the training process of the convolutional neural network.\n",
    "    \"\"\"\n",
    "\n",
    "    # Defining the model, the optimizer, the loss function, the learning rate scheduler and the early stopper\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = ResNet34()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum = MOMENTUM, nesterov = True, weight_decay = WEIGHT_DECAY)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience = SCHEDULER_PATIENCE, factor = SCHEDULER_FACTOR, verbose = True)\n",
    "    early_stopper = Early_Stopper(callback = early_callback)\n",
    "\n",
    "    # Defining lists to keep track of the training process\n",
    "    train_accuracies_history = []\n",
    "    train_losses_history = []\n",
    "    eval_accuracies_history = []\n",
    "    eval_losses_history = []\n",
    "\n",
    "    # Checking if a checkpoint is available\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        checkpoint = load_checkpoint(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        tracking_lists = checkpoint['tracking']\n",
    "        early_stopper.counter = checkpoint['early_patience']\n",
    "\n",
    "        # Mover los tensores del estado del optimizador al dispositivo cuda\n",
    "        for state in optimizer.state.values():\n",
    "            for key, value in state.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    state[key] = value.to(device)\n",
    "                    \n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        tracking_lists = {\n",
    "            'train_accuracies': train_accuracies_history,\n",
    "            'train_losses': train_losses_history,\n",
    "            'eval_accuracies': eval_accuracies_history,\n",
    "            'eval_losses': eval_losses_history\n",
    "        }\n",
    "\n",
    "    # Defining the data loaders\n",
    "    loaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader\n",
    "    }\n",
    "\n",
    "    print(start_epoch)\n",
    "\n",
    "    # Training the model\n",
    "    postrained_tracking_lists, val_predictions, val_targets = train(model, loaders, optimizer, criterion, scheduler, tracking_lists, callback, early_stopper, start_epoch, epochs = EPOCHS, device = device)\n",
    "\n",
    "execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
